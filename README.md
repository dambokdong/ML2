# ML2 Take-Home Project: ECG Classification

## Overview 
The task given is a multiclass classification problem, where the class distribution of the training data is highly imbalanced. Nature of the data is a segmented time-series, where each sample row is 187-element vector containing the ECG lead II signal for one heartbeat. The last column denotes the class to which a sample belongs. Labels [0, ..., 4] correspond to ['N', 'S', 'V', 'F', 'Q'] respectively, with number of samples for each class being [90589, 2779, 7236, 803, 8039].

First, we aim to handle the imbalance in the dataset via oversampling. We test 5-different methods of oversampling, from random upsampling to SMOTE-based methodologies. Brief description for each is included in the section <Oversampling Methods>

Next, we implement the 1D Convolutional Neural Network model to tackle the classification problem. We feed different sets of training data generated by each oversampling method and evalate against the test set. Description of the model can be found in the section <Model>. 

Lastly, model performance is gauged by different evaluation metrics with consideration to the imbalanced nature of the data. We compare how different oversampling methods affect the model performance. We see [ list of metrics ] as more significant metrics, hence will be our focus. 

## Oversampling Methods 
- Random Upsampling: This method balances the dataset by generating duplicates of random datapoints in minority classes. 
- SMOTE: Rather than duplicating the existing datapoint, this method generates synthetic datapoints via linear combination of the original datapoint and randomly chosen datapoint amongst its nearest neighbors. 
- Borderline SMOTE: This method aims to improve the original SMOTE by focusing on 'dangerous' datapoints, hence performs SMOTE soley on these datapoints.
- ADASYN: This method also aims to improve the SMOTE by giving different importance to datapoints depending on the 'density' of minority datapoints. More synthetic samples are created in the region where minority class is scarce, and vice versa. 
- KMeans SMOTE: The entire dataset is first clustered into pre-set number of clusters, then SMOTE is performed across these clusters with more weights given to the clusters with lesser population of minority.

## Model
The original model was referred from { kaggle notebook link }. 

Model consists of:  
  - 3 sets of 1-D convolutional layer with a batch normalization and a max pool layer. 
  - 1 fully-connected layer
  - 1 linear layer with softmax output
  - No regularization was used except for early stopping

## Performance Evaluation
- Description of Each : Confusion Matrix + Imbalanced Metrics  
- Important Metrics : 
- Which oversampling performed the best? 

All models exhibited sufficient capacity to learn the training distribution with high accuracy. The error rates for all models were highest for the classes with the fewest examples. Collecting more data for the S- and F-type arrhythmias would likely increase the overall accuracy of the trained models.

## References 
